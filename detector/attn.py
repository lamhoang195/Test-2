import numpy as np
import time
from tqdm import tqdm

from .utils import process_attn, calc_attn_score


class AttentionDetector():
    def __init__(self, model, pos_examples=None, neg_examples=None, use_token="first_5", instruction="Say xxxxxx", threshold=0.5):
        self.name = "attention"
        self.attn_func = "normalize_sum"
        self.model = model
        self.important_heads = model.important_heads
        self.instruction = instruction
        self.use_token = use_token
        self.threshold = threshold
        
        # T·ª± ƒë·ªông t√¨m decay rate t·ªëi ∆∞u n·∫øu c√≥ d·ªØ li·ªáu training
        if pos_examples and neg_examples and use_token == "first_5":
            self.optimal_decay = self._find_optimal_decay(pos_examples[:5], neg_examples[:5])  # Ch·ªâ test v·ªõi √≠t samples
        else:
            self.optimal_decay = 0.7  # Default decay rate
        if pos_examples and neg_examples:
            pos_scores, neg_scores = [], []
            for prompt in tqdm(pos_examples, desc="pos_examples"):
                _, _, attention_maps, _, input_range, generated_probs = self.model.inference(
                    self.instruction, prompt, max_output_tokens=5
                )
                pos_scores.append(self.attn2score(attention_maps, input_range))

            for prompt in tqdm(neg_examples, desc="neg_examples"):
                _, _, attention_maps, _, input_range, generated_probs = self.model.inference(
                    self.instruction, prompt, max_output_tokens=5
                )
                neg_scores.append(self.attn2score(attention_maps, input_range))

            self.threshold = (np.mean(pos_scores) + np.mean(neg_scores)) / 2

        if pos_examples and not neg_examples:
            pos_scores = []
            for prompt in tqdm(pos_examples, desc="pos_examples"):
                _, _, attention_maps, _, input_range, generated_probs = self.model.inference(
                    self.instruction, prompt, max_output_tokens=5
                )
                pos_scores.append(self.attn2score(attention_maps, input_range))

            self.threshold = np.mean(pos_scores) - 4 * np.std(pos_scores)

    def _find_optimal_decay(self, pos_examples, neg_examples):
        """T√¨m decay rate t·ªëi ∆∞u t·ª´ 0.5 ƒë·∫øn 0.9"""
        best_decay = 0.7
        best_accuracy = 0
        
        for decay in [0.5, 0.6, 0.7, 0.8, 0.9]:
            accuracy = self._evaluate_decay(decay, pos_examples, neg_examples)
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_decay = decay
        
        print(f"üéØ Optimal decay rate: {best_decay} (accuracy: {best_accuracy:.3f})")
        return best_decay
    
    def _evaluate_decay(self, decay, pos_examples, neg_examples):
        """ƒê√°nh gi√° accuracy v·ªõi decay rate cho tr∆∞·ªõc"""
        correct = 0
        total = 0
        
        for prompt in pos_examples:
            _, _, attention_maps, _, input_range, _ = self.model.inference(
                self.instruction, prompt, max_output_tokens=5
            )
            score = self._calculate_weighted_score(attention_maps, input_range, decay)
            if score <= 0.5:  # Temporary threshold
                correct += 1
            total += 1
        
        for prompt in neg_examples:
            _, _, attention_maps, _, input_range, _ = self.model.inference(
                self.instruction, prompt, max_output_tokens=5
            )
            score = self._calculate_weighted_score(attention_maps, input_range, decay)
            if score > 0.5:  # Temporary threshold
                correct += 1
            total += 1
        
        return correct / total if total > 0 else 0
    
    def _calculate_weighted_score(self, attention_maps, input_range, decay):
        """T√≠nh score v·ªõi exponential decay weights"""
        attention_maps = attention_maps[:5]  # Ch·ªâ l·∫•y 5 tokens
        scores = []
        
        for attention_map in attention_maps:
            heatmap = process_attn(attention_map, input_range, self.attn_func)
            score = calc_attn_score(heatmap, self.important_heads)
            scores.append(score)
        
        if len(scores) > 0:
            # Exponential decay weights: [1.0, decay, decay^2, decay^3, decay^4]
            weights = [decay ** i for i in range(len(scores))]
            weighted_sum = sum(score * weight for score, weight in zip(scores, weights))
            total_weight = sum(weights)
            return weighted_sum / total_weight
        return 0

    def attn2score(self, attention_maps, input_range):
        if self.use_token == "first":
            attention_maps = [attention_maps[0]]
            scores = []
            for attention_map in attention_maps:
                heatmap = process_attn(attention_map, input_range, self.attn_func)
                score = calc_attn_score(heatmap, self.important_heads)
                scores.append(score)
            return sum(scores) if len(scores) > 0 else 0
        
        elif self.use_token == "first_5":
            return self._calculate_weighted_score(attention_maps, input_range, self.optimal_decay)
        
        else:
            # Fallback: use all tokens with equal weights
            scores = []
            for attention_map in attention_maps:
                heatmap = process_attn(attention_map, input_range, self.attn_func)
                score = calc_attn_score(heatmap, self.important_heads)
                scores.append(score)
            return sum(scores) if len(scores) > 0 else 0

    def detect(self, data_prompt):
        # Measure generation time
        start_time = time.time()
        
        max_tokens = 5 if self.use_token == "first_5" else None
        generated_text, _, attention_maps, _, input_range, _ = self.model.inference(
            self.instruction, data_prompt, max_output_tokens=max_tokens)
        
        end_time = time.time()
        generation_time = end_time - start_time

        focus_score = self.attn2score(attention_maps, input_range)
        return bool(focus_score <= self.threshold), {
            "focus_score": focus_score,
            "generated_text": generated_text,
            "generation_time": generation_time
        }
    
    def detect_fast(self, data_prompt):
        """Fast detection using optimized inference"""
        # Measure generation time
        start_time = time.time()
        
        # S·ª≠ d·ª•ng inference_fast n·∫øu c√≥, n·∫øu kh√¥ng fallback v·ªÅ inference
        max_tokens = 5 if self.use_token == "first_5" else None
        if hasattr(self.model, 'inference_fast'):
            generated_text, _, attention_maps, _, input_range, _ = self.model.inference_fast(
                self.instruction, data_prompt, max_output_tokens=max_tokens)
        else:
            generated_text, _, attention_maps, _, input_range, _ = self.model.inference(
                self.instruction, data_prompt, max_output_tokens=max_tokens)
        
        end_time = time.time()
        generation_time = end_time - start_time

        focus_score = self.attn2score(attention_maps, input_range)
        return bool(focus_score <= self.threshold), {
            "focus_score": focus_score,
            "generated_text": generated_text,
            "generation_time": generation_time
        }
